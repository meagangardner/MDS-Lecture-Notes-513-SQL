{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"img/dsci513_header2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 1: Introduction to relational databases\n",
    "\n",
    "Total out of 51.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "---\n",
    "rubric={mechanics:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)\n",
    "\n",
    "- You submit 3 files to Gradescope (***upload it separately, not as a zip file, or folder***)\n",
    "    - Fully rendered ipynb notebook, \n",
    "    - HTML of the fully rendered ipynb notebook\n",
    "    - PDF of the fully rendered ipynb notebook\n",
    "\n",
    "- Add a link to your GitHub repository here:\n",
    "\n",
    "> NOTE: There is no autograding for any of our labs. So, the idea of Gradescope is just to upload the 3 files listed above. You just need to make sure that it is uploaded. You must upload 3 files individually to Gradescope (not in a folder or a zipped folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configurations\n",
    "---\n",
    "\n",
    "You must load the data to your database before you start this lab. You can find the dump file in the [databases](https://github.ubc.ca/MDS-2023-24/DSCI_513_database-data-retr_students/tree/master/databases) folder in the student repo. If you are unsure about this, look into themes from lecture 1 and [watch the video here (also linked there)](https://ubc.zoom.us/rec/share/tOEG6lC_UMwU2HwB7FmKM37pn8lsV2akjljdILimugAcLVDk_MCZveXi0QFrvRZv.acfizhf2nv6E4Sgi?startTime=1699495664000). (Passcode: `s^T3E@1N`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql\n",
    "%config SqlMagic.displaylimit = 20\n",
    "%config SqlMagic.autolimit = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the following cell, make sure that you have the correct login information in the `credentials.json` file:\n",
    "\n",
    "> You should be careful where your credentials file is `credentials.json`. Revise concepts on absolute path and relative path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "with open('data/credentials.json') as f:\n",
    "    login = json.load(f)\n",
    "    \n",
    "username = login['user']\n",
    "password = urllib.parse.quote(login['password'])\n",
    "host = login['host']\n",
    "port = login['port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following cell (and duplicate it as needed) to connect to the database that you need for a question. Remember that if you're using the same database for a few questions, you don't need to reconnect each time. Only use the following cell for establishing the first connection, and for when you want to switch from one to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://{username}:{password}@{host}:{port}/imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Getting to know a database\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise does not involve any coding, just getting to know our way around in pgAdmin and `psql`. You can use either of these two options for answering the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the name of tables that exist in the `imdb` and `world` databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the column names of the `country` table in the `world` database.\n",
    "\n",
    "> **Hint**: You can find the answer using pgAdmin by right-clicking the table name and selecting \"Properties\", but you can also use one of `psql`'s meta commands to do this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many **unique** data types do you see in the `country` table of the `world` database? List those unique datatypes.\n",
    "\n",
    "> Remember? The datatype of each column in a table determines its **domain** of allowable values the column can store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "\n",
    "rubric={accuracy:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows are there in the `names` table of the `imdb` database? Use pgAdmin to answer this question. \n",
    "\n",
    "> **Hint:** Right-click on the table in pgAdmin and inspect the options you have. Also, you might want to check out the \"Properties\" tab in pgAdmin for your table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Basic SQL queries\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that returns 5 rows from the columns `title`, `start_year`, and `rating` from the `movies` table in the `imdb` database.\n",
    "\n",
    "How are the rows ordered by default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to retrieve rows corresponding to the 10 top-rated movies in 2015 (year based on the `start_year` column) using the `movies` table in the `imdb` database, but we only want those movies that have at least 10,000 votes.\n",
    "\n",
    "> **Hint:** When trying to come up with a SQL statement for a given query, it's helpful to ask yourself these questions:\n",
    "> - Which columns to retrieve?\n",
    "> - Which table to choose columns from?\n",
    "> - What filters (if any)?\n",
    "> - Need to sort the results?\n",
    "> - Duplicates ok?\n",
    "> - How many rows to retrieve? As many as there are, or a specific number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "\n",
    "rubric={accuracy:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find out what percentage of movies in the `imdb` database are rated no less than 7. Write a query that computes that percentage value with two digits after the decimal point, and prints the output as e.g. `10.25%`.\n",
    "\n",
    "For this question, write one query to find the total count, and use the result manually in another query to compute the percentage (You will learn how to do this in a single query soon!).\n",
    "\n",
    "> **Hint:** There is a SQL function for rounding numbers, remember?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to the `world` database that returns all unique pairs of continents and regions in the `country` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql postgresql://{username}:{password}@{host}:{port}/world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to the `world` database that returns the **number** of unique pairs of continents and regions in the `country` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6\n",
    "\n",
    "rubric={accuracy:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Query the `country` table from the `world` database to find the population density (i.e. `(population) / (surface area)`) for every country located in Asia, Africa, and Europe.\n",
    "- Name the resulting column `pop_density`, and round its values to 1 decimal digit.\n",
    "- Your query should return the `name`, `region`, and `pop_density` columns only.\n",
    "- Sort the resulting rows by `pop_density` in descending order.\n",
    "\n",
    "> **Hint:** Some SQL functions don't work with inexact data types, so you'll need to do a type conversion to get the right result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7\n",
    "\n",
    "rubric={accuracy:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the `country` table of the `world` database, retrieve the name and percent change in GNP (gross national product) of countries which experienced between 0 and 50% increase in their GNP. The percent change in GNP, $\\epsilon_\\text{GNP}$, is given by\n",
    "\n",
    "$$\n",
    "\\epsilon_\\text{GNP} = \\frac{\\text{GNP} - \\text{GNP}_\\text{old}}{\\text{GNP}_\\text{old}} \\times 100\n",
    "$$\n",
    "\n",
    "- Round $\\epsilon_\\text{GNP}$ to 1 decimal digit, and show $\\epsilon_\\text{GNP}$ as, for example, `100.0%` (i.e. append a percent sign to the value).\n",
    "- The column containing $\\epsilon_\\text{GNP}$ values should have the column name \"**GNP % change**\".\n",
    "- Sort your results by $\\epsilon_\\text{GNP}$ in descending order.\n",
    "- Eliminate rows which contain null values for $\\epsilon_\\text{GNP}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the countries retrieved in [Exercise 2.7](#2.7) have gained independence after 1950? Write a query that answers this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 (Challenging Question)\n",
    "\n",
    "> **Note:** This question is challenging, and is meant to be attempted after you have completed the rest of the assignment (from all courses). Don't stress out if you can't solve it!\n",
    " \n",
    "rubric={accuracy:1.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a query that returns the names of all countries that gained independence at some point in time (i.e. have a recorder independence year).\n",
    "- We also like to have a column named `Independent for (years):` which computes the number of years since independence until now (in integer values). \n",
    "- Don't hard-code current year, e.g. 2021, in the query; we want our query to be useful in upcoming years too.\n",
    "- Sort your results alphabetically by country name in ascending order.\n",
    "\n",
    "> **Hint:** Watch out for nulls!\n",
    "\n",
    "> **Hint:** There are several solutions to this exercise, and all of them are acceptable as long as your query returns the correct rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 (Challenging Question)\n",
    "\n",
    "> **Note:** This question is challenging, and is meant to be attempted after you have completed the rest of the assignment (from all courses). Don't stress out if you can't solve it!\n",
    "\n",
    "rubric={accuracy:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following SQL query finds the number of countries in Asia:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    COUNT(country)\n",
    "FROM\n",
    "    country\n",
    "WHERE\n",
    "    continent = 'Asia'\n",
    ";\n",
    "```\n",
    "\n",
    "Rewrite this query to obtain the same result without using a `WHERE` clause.\n",
    "\n",
    "**Hint:** Think about how `COUNT()` treats certain data types differently..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Pattern matching\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query to find the country names both starting and ending with a vowel (i.e. \"a\", \"e\", \"i\", \"o\", and \"u\"). Also, discard names with more than one part (e.g. \"United Kingdom\"). Do not use regex for this question.\n",
    "\n",
    "> **Hint:** You might initially think of `LIKE` keyword for finding names starting and ending with a vowel. It is certainly possible to answer this question using `LIKE`, but it would be an unnecessarily long query. Think about how you can \"index\" into the names, and use that in combination with `IN` to make the query shorter. You still need `LIKE` to discard names with multiple parts though!\n",
    "\n",
    "> **Hint:** Multi-part country names have at least one space character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2\n",
    "\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given the table `country` of the `world` database, write a query to find the name of countries located in the Middle East region.\n",
    "- Along with the column `name`, your query should also retrieve a derived column named `Republic?` that is boolean valued, and shows `True` if the country is run by a republic government, and `False` if not.\n",
    "- Sort the results based on the `name` column alphabetically in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Data retrieval with `psycopg2` and Pandas\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`psycopg2` is the official Python driver for Postgres (see docs [here](https://www.psycopg.org/docs/index.html)), which allows us to send SQL queries directly to a database server and retrieve data into Python.\n",
    "\n",
    "It is actually quite easy to use `psycopg`. We first need to set up a connection to our database. Let's open up the JSON file storing our login information in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/credentials.json') as f:\n",
    "    login = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a connection, we use `psycopg2.connect()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='world',\n",
    "                        user=login['user'],\n",
    "                        password=login['password'],\n",
    "                        host=login['host'],\n",
    "                        port=login['port'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or because we've used the same names for our dictionary keys in `credentials.json` as the arguments to `psycopg2.connect()`, we can simply unpack `login` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database='world', **login)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I'm setting the argument `database` separately such that I don't have to go back and modify `credentials.json` every time I want to change the database.\n",
    "\n",
    "We'll keep this connection open for our whole working session. It's not bad to keep it open if you're not using it (it will terminate when you exit Python/Jupyter anyway), however the connection does consume system resources, so it's good practice to close it if you're finished with it, using `conn.close()`.\n",
    "\n",
    "Once we have a connection, we create `cursor` objects to perform operations and then `.execute()` a SQL statement. For various reasons which you can read more about in the [psycopg2 docs](https://www.psycopg.org/docs/usage.html#transactions-control), it's recommended to use Python's context managing `with` statement to create cursors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT * FROM country LIMIT 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the returned data we can use one of three methods:\n",
    "- `cur.fetchone()`: returns a single row\n",
    "- `cur.fetchmany(5)`: returns the specified numbers of rows\n",
    "- `cur.fetchall()`: returns all rows\n",
    "\n",
    "But note that the returned data is like a generator, as you call the above methods, you'll iterate over the data. If you've iterated over all the rows, then running one of the above methods won't return anything, you'd need to run the `execute` statement again. The reason for this behaviour is to avoid reading all the returned data into memory at once. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT name, population FROM country LIMIT 5\")\n",
    "    for row in cur.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I try iterate over 6 rows in this case, I'll get `None` back once all my data is exhausted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT name, population FROM country LIMIT 5\")\n",
    "    for i in range(6):\n",
    "        print(cur.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even execute queries that are broken over multiple lines for readability using Python's triple quote delimiters (`\"\"\"text\"\"\"`) for multi-line comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  name, region, population\n",
    "FROM\n",
    "  country\n",
    "LIMIT 5\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "with conn, conn.cursor() as cur:\n",
    "    cur.execute(query)\n",
    "    for row in cur.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to it! Once we're done, we can close our connection to save system resources by running `conn.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** If you get an error: `InternalError: current transaction is aborted, commands ignored until end of transaction block` that means that you didn't use the `with` context manager correctly. To get out of this state, run `conn.rollback()`. You can read more about why you need to do this in the [psycopg2 docs](https://www.psycopg.org/docs/usage.html#transactions-control)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL and Pandas\n",
    "\n",
    "`psycopg2` provides a basic interface with a Postgres database. As data scientists, you'll often be working with data in a Pandas dataframe so it would be useful to be able to execute SQL statements and coerce the returned data directly into a dataframe. As we've seen in lecture 1, it is also possible to convert the returned data into a dataframe with `ipython-sql`, but we also need to be able to do that without a Jupyter notebook environment as well.\n",
    "\n",
    "Luckily, this is super easy to do with the pandas functions `pd.read_sql_query()`. Let's give it a try. First we need to create a connection to our database. We can do this using our already existing `psycopg2` connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  name, region, population\n",
    "FROM\n",
    "  country\n",
    "LIMIT 5\n",
    ";\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to avoid the above warning from Pandas, you can also create a connection using the `sqlalchemy` package instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "conn2 = create_engine(f'postgresql://{username}:{password}@{host}:{port}/world')\n",
    "\n",
    "pd.read_sql_query(query, conn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1\n",
    "\n",
    "rubric={accuracy:2,viz:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a graph that contains the overlay of two histograms showing the distribution of \"life expectancy\", one for both continents of North and South America (collectively called \"Americas\"), and another for the continent of Europe.\n",
    "- Extract your data from the `country` table in the `world` database.\n",
    "- Filtering of the data must be done using SQL queries executed through `psycopg2`.\n",
    "- As for the formatting of the graph, please follow the [general visualization rubric](https://github.com/UBC-MDS/public/blob/55c2d336bb91e38301c9e9d025faf284449ca272/rubric/rubric_viz.md). You can use any bin size that you see fit for your histograms. Use any visualization package that you like.\n",
    "\n",
    "Following is an example on how you need to proceed:\n",
    "\n",
    "```\n",
    "def exec_query(query):\n",
    "    \"\"\"Reads a SQL query and returns retrieved tuples as a list.\"\"\"\n",
    "\n",
    "    with conn, conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        return cur.fetchall()\n",
    "\n",
    "\n",
    "result = exec_query(\"\"\"\n",
    "<your Query here>\n",
    "\"\"\")\n",
    "lifeexp_america = [i[0] for i in result]  # take values out of returned tuples\n",
    "\n",
    "result = exec_query(\"\"\"\n",
    "<your Query here>\n",
    "\"\"\")\n",
    "lifeexp_europe = [i[0] for i in result]  \n",
    "\n",
    "# plot your data here\n",
    "You are free to use any visualization package that you like for all viz-related questions in all labs. But the environment that you are using only has matplotlib installed. So, if you plan to use other packages, you need to install them first and take responsibility for that.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here based on the above instructions and examples.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2\n",
    "\n",
    "rubric={accuracy:2,viz:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a bar graph that shows the average life expectancy of each continent.\n",
    "- Your plot should also show the standard deviation of life expectancy for each continent as an error bar.\n",
    "- Use Pandas aggregators to obtain averages and the standard deviations after retrieving data using SQL.\n",
    "- Also, remember to exclude rows that contain null values for life expectancy.\n",
    "\n",
    "> There are no helpers here, but you got the idea of how to approach it from previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here based on the above instructions.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3\n",
    "\n",
    "rubric={accuracy:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the `world` database, which are the 10 most spoken languages in the world? Note that each language in a country is spoken by a particular percentage of the population.\n",
    "\n",
    "Answering this question involves retrieving and combining data from multiple tables, as well as grouping and aggregation. Since we have not talked about either combining tables or grouping and aggregation in SQL yet, you need to do the retrieval part using SQL and the remaining parts using Pandas. My solution involves the following steps:\n",
    "\n",
    "1. Use SQL queries to retrieve data from 2 different tables, and load the data into 2 Pandas dataframes using `pd.read_sql_query()`\n",
    "2. Merge the tables using Pandas `.merge()` function that you've learned in DSCI 511\n",
    "3. Create a new column for your dataframe to take into account the population percentages speaking a particular language\n",
    "4. Drop unnecessary columns\n",
    "5. Use Pandas functions `.groupby()` together with `.agg()`\n",
    "\n",
    "For your SQL queries, only retrieve the columns that you need.\n",
    "\n",
    "Your final result should look something like this:\n",
    "\n",
    "| **language** | **speaking_population** |\n",
    "|--------------|-------------------------|\n",
    "| **lang1**    | 123456789               |\n",
    "| **lang2**    | 123456789               |\n",
    "| **lang3**    | 123456789               |\n",
    "| ...          | ...                     |\n",
    "\n",
    "(Note that you will get multiple column indexes because of grouping in Pandas, so your `speaking_population` column header will visually look _raised_ which is hard to reproduce in markdown. Don't worry if this happens, as it is supposed to.)\n",
    "\n",
    "> **Note:** In order for merging to be possible in Pandas, column names should be the same. Think of how you can write your SQL query such that you have the same column names, based on which you want to do the merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('dsci513')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lecture Outline",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "8073f1d470671f8d2d6e6e13c5af44e5d73d4aa71f13e30ba505754708c6b86f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
